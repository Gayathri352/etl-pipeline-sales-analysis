# ğŸ“Š ETL Pipeline for Sales Data Analysis

This project showcases an **end-to-end ETL pipeline** built using Python, Apache Airflow, and PostgreSQL to process and analyze daily sales data from multiple sources.

---

## ğŸš€ Features

- Automated ingestion from CSV files and REST APIs
- Data transformation and loading into PostgreSQL
- Integrated **Great Expectations** for data quality checks
- Interactive Power BI dashboard for business insights

---

## ğŸ—‚ï¸ Folder Structure

```
etl-pipeline-sales-analysis/
â”œâ”€â”€ dags/                      # Airflow DAGs
â”œâ”€â”€ sql/                       # SQL scripts
â”œâ”€â”€ expectations/              # Great Expectations validations
â”œâ”€â”€ dashboards/                # Power BI or mock-up dashboards
â”œâ”€â”€ data/                      # Sample sales data
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## âš™ï¸ Technologies Used

- Python, Apache Airflow
- PostgreSQL
- Great Expectations
- Power BI
- REST APIs, CSV

---

## ğŸ“ˆ Outcome

- Automated daily ETL processing
- Real-time data validation
- Clean dashboards with **product performance** and **sales trends**

---

## ğŸ How to Run (Locally Simulated)

1. Place sample sales CSVs in the `/data` folder
2. Configure and start Airflow scheduler
3. Run DAG from `/dags/sales_etl_dag.py`
4. Visualize processed data using Power BI dashboards

---

## ğŸ“© Contact

**Sai Gayathri Makineni**  
Graduate Student, Computer Science â€“ University of North Texas  
ğŸ“§ [your email]  
ğŸŒ [LinkedIn link]
